"""
run_debug_pipeline.py â€” Cháº¡y 1 áº£nh qua toÃ n pipeline, lÆ°u káº¿t quáº£ tá»«ng bÆ°á»›c.

Má»—i láº§n cháº¡y: dá»n sáº¡ch output/debug_run/ trÆ°á»›c â†’ lÆ°u rÃµ tá»«ng bÆ°á»›c Ä‘á»ƒ xem.

Steps:
  step-1_input.jpg          â† áº¢nh gá»‘c crop
  step-2_deskewed.png       â† Sau deskew (chá»‰ lÆ°u náº¿u bá»‹ nghiÃªng)
  step-2_fixed.png          â† Sau AI fix 180Â°
  step-3_detection.png      â† PaddleOCR bbox overlay
  step-3_ocr.json           â† OCR JSON (text + bbox)
  step-3_ocr.txt            â† OCR raw text (1 dÃ²ng/block)
  step-4_grouped.json       â† Sau khi merge_same_line + group_drug_lines
  step-4_grouped.txt        â† Grouped text (dá»… Ä‘á»c)
  step-5_drug_mapper.json   â† Káº¿t quáº£ DrugMapper
  step-5_drug_mapper.txt    â† Chá»‰ cÃ¡c thuá»‘c matched
  summary.txt               â† Tá»•ng káº¿t toÃ n bá»™

Cháº¡y:
  python scripts/run_debug_pipeline.py [--gpu] [--image mask|bbox]
"""

import json
import logging
import os
import shutil
import sys
import time
from pathlib import Path

import cv2

sys.path.insert(0, str(Path(__file__).parent.parent))

# Fix PaddlePaddle MKLDNN bug
os.environ.setdefault("FLAGS_enable_pir_api", "0")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
)
logger = logging.getLogger("debug_pipeline")

DEBUG_DIR = "output/debug_run"
SAMPLE_IMG = "IMG_20260209_180420"


# â”€â”€ BÆ°á»›c 0: Dá»n dáº¹p â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def clean_debug_dir():
    """XÃ³a háº¿t káº¿t quáº£ cÅ© trÆ°á»›c khi cháº¡y."""
    if os.path.isdir(DEBUG_DIR):
        shutil.rmtree(DEBUG_DIR)
    os.makedirs(DEBUG_DIR)
    logger.info(f"Cleaned: {DEBUG_DIR}/")


# â”€â”€ BÆ°á»›c 1: Load áº£nh â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def step0_yolo(raw_path: str):
    """Step 0: YOLO detection + crop (náº¿u input lÃ  raw image)."""
    from core.detector import PrescriptionDetector
    from core.segmentation import crop_by_mask

    img = cv2.imread(raw_path)
    if img is None:
        logger.error(f"Cannot read: {raw_path}")
        sys.exit(1)

    detector = PrescriptionDetector()
    results = detector.predict(img)

    if not results or results[0].masks is None:
        logger.error("YOLO: No prescription detected!")
        sys.exit(1)

    cropped = crop_by_mask(img, results[0])
    if cropped is None:
        logger.error("YOLO: crop failed")
        sys.exit(1)

    cv2.imwrite(
        os.path.join(DEBUG_DIR, "step-0_yolo_crop.jpg"), cropped
    )
    logger.info(
        f"Step 0 âœ… YOLO: {img.shape[1]}x{img.shape[0]}"
        f" â†’ {cropped.shape[1]}x{cropped.shape[0]}"
    )
    return cropped


def step1_load(input_type="mask", raw_path=None):
    """Load áº£nh: tá»« pre-cropped hoáº·c raw+YOLO."""
    if raw_path:
        # Cháº¡y YOLO Ä‘á»ƒ crop
        img = step0_yolo(raw_path)
    else:
        path = (
            f"data/output/{input_type}/"
            f"{SAMPLE_IMG}_{input_type}.png"
        )
        if not os.path.isfile(path):
            logger.error(f"Not found: {path}")
            sys.exit(1)
        img = cv2.imread(path)

    cv2.imwrite(
        os.path.join(DEBUG_DIR, "step-1_input.jpg"), img
    )
    logger.info(
        f"Step 1 âœ… Input: {img.shape[1]}x{img.shape[0]}"
    )
    return img


# â”€â”€ BÆ°á»›c 2: Preprocess â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def step2_preprocess(image):
    from core.preprocessor.orientation import preprocess_image
    processed, info = preprocess_image(image, stem="step-2", save_dir=DEBUG_DIR)
    logger.info(
        f"Step 2 âœ… Preprocess: "
        f"deskew={info['deskew_angle']}Â°, "
        f"portrait={info['portrait_rotated']}, "
        f"ai={info['ai_status']}"
    )
    return processed, info


# â”€â”€ BÆ°á»›c 3: OCR â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def step3_ocr(image, use_gpu=False):
    from core.ocr.ocr_engine import HybridOcrModule

    device = "cuda" if use_gpu else "cpu"

    # Resize náº¿u áº£nh quÃ¡ lá»›n (trÃ¡nh PaddleOCR OOM)
    MAX_DIM = 1600
    h, w = image.shape[:2]
    if max(h, w) > MAX_DIM:
        scale = MAX_DIM / max(h, w)
        new_w, new_h = int(w * scale), int(h * scale)
        image = cv2.resize(image, (new_w, new_h),
                           interpolation=cv2.INTER_LINEAR)
        logger.info(f"  Resized: {w}x{h} â†’ {new_w}x{new_h} "
                    f"(scale={scale:.2f})")
        cv2.imwrite(
            os.path.join(DEBUG_DIR, "step-3_resized.png"), image
        )

    module = HybridOcrModule(device=device)
    result = module.extract(image, input_type="mask")

    # Detection overlay
    module.save_results(
        result, image, "step-3",
        DEBUG_DIR, DEBUG_DIR, DEBUG_DIR,
    )
    # Rename generated files â†’ step-3_* names
    for old, new in [
        ("step-3_det.png", "step-3_detection.png"),
    ]:
        src = os.path.join(DEBUG_DIR, old)
        dst = os.path.join(DEBUG_DIR, new)
        if os.path.exists(src):
            os.replace(src, dst)

    # Save JSON
    ocr_dict = {
        "module": result.module_name,
        "elapsed_ms": result.elapsed_ms,
        "block_count": len(result.text_blocks),
        "blocks": [
            {
                "text": b.text,
                "confidence": round(b.confidence, 4),
                "bbox": b.bbox,
            }
            for b in result.text_blocks
        ],
    }
    json_path = os.path.join(DEBUG_DIR, "step-3_ocr.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(ocr_dict, f, ensure_ascii=False, indent=2)

    # Save txt (1 block per line)
    txt_path = os.path.join(DEBUG_DIR, "step-3_ocr.txt")
    with open(txt_path, "w", encoding="utf-8") as f:
        for i, b in enumerate(result.text_blocks):
            f.write(f"[{i:02d}] {b.text}\n")

    logger.info(
        f"Step 3 âœ… OCR: {len(result.text_blocks)} blocks "
        f"in {result.elapsed_ms:.0f}ms"
    )
    return result, json_path


# â”€â”€ BÆ°á»›c 4: Grouping â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def step4_grouping(ocr_json_path):
    """Ãp dá»¥ng merge_same_line + group_drug_lines, lÆ°u trÆ°á»›c/sau Ä‘á»ƒ so sÃ¡nh."""
    from core.converter.ocr_to_pima import OcrToPimaConverter

    with open(ocr_json_path, encoding="utf-8") as f:
        data = json.load(f)
    raw_blocks = data["blocks"]

    # BÆ°á»›c 4a: merge same-line
    same_line = OcrToPimaConverter.merge_same_line_blocks(raw_blocks)
    # BÆ°á»›c 4b: cross-line drug grouping
    grouped = OcrToPimaConverter.group_drug_lines(same_line)

    # Save JSON
    grouped_json = {
        "raw_count": len(raw_blocks),
        "after_same_line": len(same_line),
        "after_grouping": len(grouped),
        "blocks": [
            {
                "text": b.get("text", ""),
                "confidence": b.get("confidence", 0),
            }
            for b in grouped
        ],
    }
    json_path = os.path.join(DEBUG_DIR, "step-4_grouped.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(grouped_json, f, ensure_ascii=False, indent=2)

    # Save txt â€” dá»… Ä‘á»c
    txt_path = os.path.join(DEBUG_DIR, "step-4_grouped.txt")
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(f"Raw blocks:      {len(raw_blocks)}\n")
        f.write(f"After same-line: {len(same_line)}\n")
        f.write(f"After grouping:  {len(grouped)}\n")
        f.write("-" * 40 + "\n")
        for i, b in enumerate(grouped):
            f.write(f"[{i:02d}] {b.get('text', '')}\n")

    logger.info(
        f"Step 4 âœ… Grouping: "
        f"{len(raw_blocks)} raw â†’ {len(same_line)} same-line "
        f"â†’ {len(grouped)} final"
    )
    return grouped


# â”€â”€ BÆ°á»›c 5: DrugMapper â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def step5_drug_mapper(grouped_blocks):
    from core.converter.drug_lookup import DrugLookup

    lookup = DrugLookup()  # Local VN DB only
    results = []
    matched = []

    # Keywords chá»‰ ra block NOT pháº£i tÃªn thuá»‘c
    SKIP_PATTERNS = {
        "bá»™ y táº¿", "Ä‘Æ¡n thuá»‘c", "Ä‘iá»‡n thoáº¡i", "há» tÃªn", "tuá»•i",
        "giá»›i tÃ­nh", "mÃ£ sá»‘", "bhyt", "Ä‘á»‹a chá»‰", "cháº©n Ä‘oÃ¡n",
        "cháº¥n Ä‘oÃ¡n", "stt", "thuá»‘c Ä‘iá»u trá»‹", "thuoc", "van co",
        "vÄƒn cÆ¡", "bvÄ‘k", "bá»‡nh viá»‡n",
    }
    MIN_SCORE = 0.3   # Bá» qua káº¿t quáº£ khÃ´ng Ä‘á»§ tin cáº­y

    for b in grouped_blocks:
        # Skip dosage blocks
        if b.get("label") == "dosage":
            continue
        text = b.get("text", "").strip()
        if not text or len(text) < 5:
            continue

        # Skip header/non-drug blocks
        text_lower = text.lower()
        if any(kw in text_lower for kw in SKIP_PATTERNS):
            continue

        r = lookup.lookup(text)

        # Only accept results with sufficient confidence
        is_match = r["name"] and r["score"] >= MIN_SCORE
        results.append({
            "ocr_text":     text,
            "matched_drug": r["name"],
            "score":        round(r["score"], 3),
            "source":       r["source"],
            "category":     r.get("category"),
            "status":       "matched" if is_match
                            else "no_match",
        })
        if is_match:
            matched.append(r["name"])

    # Save JSON
    json_path = os.path.join(DEBUG_DIR, "step-5_drug_mapper.json")
    with open(json_path, "w", encoding="utf-8") as f:
        json.dump(results, f, ensure_ascii=False, indent=2)

    # Save txt
    txt_path = os.path.join(DEBUG_DIR, "step-5_drug_mapper.txt")
    with open(txt_path, "w", encoding="utf-8") as f:
        f.write(f"Drugs matched: {len(matched)}/{len(results)}\n")
        f.write("-" * 40 + "\n")
        for r in results:
            if r["status"] == "matched":
                src = r["source"] or ""
                f.write(
                    f"  [{src:8s}] [{r['score']:.2f}] "
                    f"'{r['ocr_text']}'"
                    f" â†’ {r['matched_drug']}\n"
                )
        f.write("\n--- All results ---\n")
        for r in results:
            mark = "âœ…" if r["status"] == "matched" else "  "
            src = r.get("source") or "-"
            f.write(
                f"{mark} [{src:8s}] "
                f"[{r['score']:.2f}] {r['ocr_text']}\n"
            )

    logger.info(
        f"Step 5 âœ… DrugMapper(API): "
        f"{len(matched)}/{len(results)} matched"
    )
    return matched, results



# â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def write_summary(prep_info, n_ocr, ms_ocr, n_grouped, matched_drugs, elapsed):
    files = sorted(os.listdir(DEBUG_DIR))
    lines = [
        "=" * 55,
        "  DEBUG PIPELINE SUMMARY",
        "=" * 55,
        f"  Image:   {SAMPLE_IMG}",
        f"  Time:    {elapsed:.1f}s total",
        "",
        f"  Step 2 â€” Preprocess",
        f"    deskew:   {prep_info['deskew_angle']}Â°",
        f"    portrait: {prep_info['portrait_rotated']}",
        f"    ai_fix:   {prep_info['ai_status']}",
        "",
        f"  Step 3 â€” OCR",
        f"    blocks:  {n_ocr}",
        f"    time:    {ms_ocr:.0f}ms",
        "",
        f"  Step 4 â€” Grouping",
        f"    final:   {n_grouped} blocks",
        "",
        f"  Step 5 â€” DrugMapper",
        f"    matched: {matched_drugs}",
        "",
        "  Files:",
    ]
    for fn in files:
        sz = os.path.getsize(os.path.join(DEBUG_DIR, fn))
        lines.append(f"    {fn:35s} {sz:>8,} bytes")
    lines.append("=" * 55)

    text = "\n".join(lines)
    with open(os.path.join(DEBUG_DIR, "summary.txt"), "w",
              encoding="utf-8") as f:
        f.write(text)
    print("\n" + text)


# â”€â”€ Main â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

def main():
    import argparse
    parser = argparse.ArgumentParser()
    parser.add_argument("--gpu", action="store_true")
    parser.add_argument("--image", default="mask",
                        choices=["mask", "bbox"])
    parser.add_argument(
        "--raw", type=str, default=None,
        help="Raw image path â†’ run YOLO first",
    )
    args = parser.parse_args()

    t0 = time.time()

    # Dá»n dáº¹p káº¿t quáº£ cÅ©
    clean_debug_dir()

    img = step1_load(args.image, raw_path=args.raw)
    processed, prep_info = step2_preprocess(img)
    result, ocr_json_path = step3_ocr(
        processed, use_gpu=args.gpu
    )
    grouped = step4_grouping(ocr_json_path)
    matched, all_results = step5_drug_mapper(grouped)

    write_summary(
        prep_info,
        n_ocr=len(result.text_blocks),
        ms_ocr=result.elapsed_ms,
        n_grouped=len(grouped),
        matched_drugs=matched,
        elapsed=time.time() - t0,
    )
    print(f"\nâœ… Done in {time.time() - t0:.1f}s")
    print(f"ğŸ“‚ {os.path.abspath(DEBUG_DIR)}/")


if __name__ == "__main__":
    main()
